# ğŸ‡¹ğŸ‡· Turkish Government Intelligence Hub

**TÃ¼rkiye'deki siyasi partilerin tÃ¼zÃ¼klerini analiz eden, tamamen lokal Ã§alÄ±ÅŸan RAG tabanlÄ± soru-cevap sistemi**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3+-green.svg)](https://www.langchain.com/)
[![Qwen](https://img.shields.io/badge/LLM-Qwen2.5--7B-orange.svg)](https://ollama.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Ä°Ã§indekiler

- [Ã–zellikler](#-Ã¶zellikler)
- [Teknoloji Stack](#-teknoloji-stack)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [Performans](#-performans)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [KatkÄ±da Bulunma](#-katkÄ±da-bulunma)
- [Lisans](#-lisans)

---

## ğŸ¯ Ã–zellikler

- âœ… **Tamamen Lokal:** Ä°nternet baÄŸlantÄ±sÄ± gerektirmez, veriler bilgisayarÄ±nÄ±zda kalÄ±r
- âœ… **Ãœcretsiz:** API key veya Ã¶deme gerektirmez
- âœ… **TÃ¼rkÃ§e Optimizasyonlu:** TÃ¼rkÃ§e embedding ve LLM modelleri kullanÄ±r
- âœ… **GPU HÄ±zlandÄ±rmalÄ±:** NVIDIA GPU desteÄŸi ile hÄ±zlÄ± yanÄ±t sÃ¼releri
- âœ… **RAG (Retrieval-Augmented Generation):** DoÄŸru ve kaynak tabanlÄ± cevaplar
- âœ… **Kolay GeniÅŸletilebilir:** Yeni parti tÃ¼zÃ¼kleri kolayca eklenebilir

---

## ğŸ› ï¸ Teknoloji Stack

### Core Framework
- **LangChain** - LLM orchestration ve RAG pipeline
- **Qwen2.5-7B-Instruct** - Lokal LLM (Alibaba)
- **Ollama** - Lokal LLM inference server

### Embeddings & Vector DB
- **HuggingFace Transformers** - TÃ¼rkÃ§e text embeddings
- **ChromaDB** - Vector database

### Document Processing
- **PyPDF** - PDF dÃ¶kÃ¼man parsing
- **RecursiveCharacterTextSplitter** - Intelligent text chunking

---

## ğŸ“¦ Kurulum

### Gereksinimler

- **Python 3.10+**
- **NVIDIA GPU** (Ã¶nerilen, CPU'da da Ã§alÄ±ÅŸÄ±r)
- **6GB+ VRAM** (RTX 3050 veya Ã¼zeri)
- **10GB+ Disk AlanÄ±**

### AdÄ±m 1: Ollama Kurulumu

1. Ollama'yÄ± indirin ve kurun:
   ```
   https://ollama.com/download/windows
   ```

2. Qwen2.5 modelini indirin:
   ```bash
   ollama pull qwen2.5:7b-instruct-q4_K_M
   ```

3. Model durumunu kontrol edin:
   ```bash
   ollama list
   ```

### AdÄ±m 2: Python OrtamÄ±nÄ± HazÄ±rlayÄ±n

1. Repository'yi klonlayÄ±n:
   ```bash
   git clone https://github.com/barancanercan/turkish-government-intelligence-hub.git
   cd turkish-government-intelligence-hub
   ```

2. Virtual environment oluÅŸturun:
   ```bash
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # Linux/Mac
   ```

3. Gereksinimleri yÃ¼kleyin:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸš€ KullanÄ±m

### Temel KullanÄ±m

```bash
python rag_qwen_local.py
```

Program Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda soru sorabilirsiniz:

```
============================================================
CHP Parti TÃ¼zÃ¼ÄŸÃ¼ - Soru-Cevap Sistemi (LOKAL QWEN)
============================================================

Sorunuz: CHP genel baÅŸkanÄ± nasÄ±l seÃ§ilir?
```

### Python Kodu ile KullanÄ±m

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.llms import Ollama
from langchain_community.vectorstores import Chroma

# 1. PDF'i yÃ¼kle
loader = PyPDFLoader("data/chp.pdf")
pages = loader.load()

# 2. Embedding modeli
embeddings = HuggingFaceEmbeddings(
    model_name="nezahatkorkmaz/turkce-embedding-bge-m3"
)

# 3. Vector database
vectorstore = Chroma.from_documents(
    documents=pages,
    embedding=embeddings,
    persist_directory="./chroma_db"
)

# 4. Lokal LLM
llm = Ollama(model="qwen2.5:7b-instruct-q4_K_M")

# 5. Soru sor
question = "CHP'nin kuruluÅŸ tarihi nedir?"
docs = vectorstore.similarity_search(question, k=3)
context = "\n".join([doc.page_content for doc in docs])

response = llm.invoke(f"Context: {context}\n\nSoru: {question}")
print(response)
```

---

## âš¡ Performans

### Test Sistemi
- **GPU:** NVIDIA RTX 3060 6GB
- **CPU:** 4 cores
- **RAM:** 9GB
- **OS:** Windows 10

### Benchmark SonuÃ§larÄ±

| Metrik | DeÄŸer |
|--------|-------|
| Ä°lk Token SÃ¼resi | 0.5-1s |
| Token/Saniye | 25-30 |
| Ortalama Cevap SÃ¼resi | 3-8s |
| VRAM KullanÄ±mÄ± | ~4GB |
| Embedding SÃ¼resi | ~2s (328 chunks) |
| Vector Search | <0.5s |

### Ã–rnek Ã‡alÄ±ÅŸtÄ±rma

```
PDF yÃ¼kleniyor...     
140 sayfa yÃ¼klendi
Metin chunk'lara bÃ¶lÃ¼nÃ¼yor...                               
328 chunk oluÅŸturuldu                                      
TÃ¼rkÃ§e Embedding Modeli yÃ¼kleniyor...            
Embedding modeli hazÄ±r                                
Vector database oluÅŸturuluyor...   
Vector database hazÄ±r

Sorunuz: CHP genel baÅŸkanÄ± nasÄ±l seÃ§ilir? 
Benzerlik hesaplanÄ±yor...
En benzer 3 bÃ¶lÃ¼m bulundu
Benzerlik skorlarÄ±: [0.77, 0.77, 0.77]
Lokal Qwen modeline gÃ¶nderiliyor...

Cevap:
CHP genel baÅŸkanÄ±, kurultayda gizli oyla ve Ã¼ye tam sayÄ±sÄ±nÄ±n 
salt Ã§oÄŸunluÄŸuyla seÃ§ilir. Ä°lk iki oylamada sonuÃ§ alÄ±namazsa, 
Ã¼Ã§Ã¼ncÃ¼ oylamanÄ±n en Ã§ok oy alan adayÄ± seÃ§ilir.
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
turkish-government-intelligence-hub/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chp.pdf              # CHP Parti TÃ¼zÃ¼ÄŸÃ¼
â”‚   â”œâ”€â”€ akp.pdf              # (Eklenecek)
â”‚   â””â”€â”€ mhp.pdf              # (Eklenecek)
â”œâ”€â”€ chroma_db/               # Vector database (otomatik oluÅŸur)
â”œâ”€â”€ rag_qwen_local.py        # Ana uygulama
â”œâ”€â”€ requirements.txt         # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ KURULUM.md              # DetaylÄ± kurulum rehberi
â””â”€â”€ README.md               # Bu dosya
```

---

## ğŸ”§ YapÄ±landÄ±rma

### Chunk BoyutlarÄ±nÄ± Ayarlama

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,        # Chunk boyutu (256-1024 arasÄ± Ã¶nerilir)
    chunk_overlap=50,      # Chunk overlap (10-20% chunk_size)
    length_function=len
)
```

### LLM Parametrelerini Ayarlama

```python
llm = Ollama(
    model="qwen2.5:7b-instruct-q4_K_M",
    temperature=0,         # YaratÄ±cÄ±lÄ±k (0.0-1.0)
    num_predict=512,       # Maksimum token
    num_ctx=4096          # Context window
)
```

### FarklÄ± Model Kullanma

```bash
# Daha kÃ¼Ã§Ã¼k model (daha hÄ±zlÄ±)
ollama pull qwen2.5:3b-instruct-q4_K_M

# Daha bÃ¼yÃ¼k model (daha kaliteli)
ollama pull qwen2.5:14b-instruct-q4_K_M
```

Kod'da:
```python
llm = Ollama(model="qwen2.5:3b-instruct-q4_K_M")  # KÃ¼Ã§Ã¼k model
```

---

## ğŸ› Sorun Giderme

### Model BulunamÄ±yor HatasÄ±

```bash
# Modeli kontrol et
ollama list

# Modeli tekrar indir
ollama pull qwen2.5:7b-instruct-q4_K_M
```

### GPU KullanÄ±lmÄ±yor

```bash
# GPU durumunu kontrol et
nvidia-smi

# Ollama'yÄ± restart et (Windows Services)
```

### VRAM Yetersiz

```python
# Daha kÃ¼Ã§Ã¼k model kullan
llm = Ollama(model="qwen2.5:3b-instruct-q4_K_M")

# Veya chunk sayÄ±sÄ±nÄ± azalt
top_k = 2  # 3 yerine 2 chunk kullan
```

---

## ğŸš§ Gelecek Ã–zellikler

- [ ] Multi-party comparison (Partileri karÅŸÄ±laÅŸtÄ±rma)
- [ ] Streamlit web UI
- [ ] Conversation history (Sohbet geÃ§miÅŸi)
- [ ] Export to PDF/DOCX
- [ ] Voice interface (Sesli soru-cevap)
- [ ] Fine-tuned Turkish political model

---

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! Pull request'lerinizi gÃ¶nderin veya issue aÃ§Ä±n.

### KatkÄ± AdÄ±mlarÄ±

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit'leyin (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

---

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

## ğŸ‘¤ GeliÅŸtirici

**Baran Can Ercan**

- ğŸŒ LinkedIn: [@barancanercan](https://www.linkedin.com/in/barancanercan)
- ğŸ“ Medium: [@barancanercan](https://barancanercan.medium.com)
- ğŸ“§ Email: barancanercan@gmail.com
- ğŸ™ GitHub: [@barancanercan](https://github.com/barancanercan)

---

## ğŸ™ TeÅŸekkÃ¼rler

- [Ollama](https://ollama.com/) - Lokal LLM inference
- [LangChain](https://www.langchain.com/) - RAG framework
- [Alibaba Qwen Team](https://qwenlm.github.io/) - Qwen2.5 model
- [HuggingFace](https://huggingface.co/) - Turkish embeddings
- [ChromaDB](https://www.trychroma.com/) - Vector database

---

## ğŸ“Š Ä°statistikler

![GitHub stars](https://img.shields.io/github/stars/barancanercan/turkish-government-intelligence-hub?style=social)
![GitHub forks](https://img.shields.io/github/forks/barancanercan/turkish-government-intelligence-hub?style=social)
![GitHub issues](https://img.shields.io/github/issues/barancanercan/turkish-government-intelligence-hub)

---

<div align="center">

**"Verilerle AydÄ±nlanan Siyaset"** ğŸ›ï¸

Made with â¤ï¸ by [Baran Can Ercan](https://github.com/barancanercan)

</div>
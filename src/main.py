"""
Turkish Government Intelligence Hub - RAG System
Basit ve temiz fonksiyonlarla organize edilmiÅŸ
"""

############################################
################ 1- IMPORT #################
############################################

from langchain_community.document_loaders import PyPDFLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.llms import Ollama
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
import warnings

warnings.filterwarnings("ignore")

############################################
############# 2- READ TO PDF ###############
############################################

def load_pdf(pdf_path):
    """PDF dosyasÄ±nÄ± yÃ¼kle"""
    print("PDF yÃ¼kleniyor...")
    loader = PyPDFLoader(pdf_path)
    pages = loader.load()
    print(f"{len(pages)} sayfa yÃ¼klendi")
    return pages

############################################
################ 3- CHUNKING ###############
############################################

def chunk_documents(pages, chunk_size=512, chunk_overlap=50):
    """DÃ¶kÃ¼manlarÄ± chunk'lara bÃ¶l"""
    print("Metin chunk'lara bÃ¶lÃ¼nÃ¼yor...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len
    )
    chunks = text_splitter.split_documents(pages)
    print(f"{len(chunks)} chunk oluÅŸturuldu")
    return chunks

############################################
########## 4- LOAD EMBEDDING MODEL #########
############################################


def load_embeddings(model_name="nezahatkorkmaz/turkce-embedding-bge-m3"):
    """TÃ¼rkÃ§e embedding modelini yÃ¼kle"""
    print("TÃ¼rkÃ§e Embedding Modeli yÃ¼kleniyor...")
    embeddings = HuggingFaceEmbeddings(model_name=model_name)
    print("Embedding modeli hazÄ±r")
    return embeddings

############################################
####### 5- CREATE VECTOR DATABASE ##########
############################################

def create_vectorstore(chunks, embeddings, persist_dir="../chroma_db"):
    """Vector database oluÅŸtur"""
    print("Vector database oluÅŸturuluyor...")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=persist_dir
    )
    print("Vector database hazÄ±r")
    return vectorstore

############################################
######### 6- SIMILARITY SEARCH #############
############################################

def search_similar_docs(vectorstore, question, top_k=3):
    """Benzer dÃ¶kÃ¼manlarÄ± bul"""
    print(f"AranÄ±yor: '{question}'")
    print("Benzerlik hesaplanÄ±yor...")
    
    relevant_docs = vectorstore.similarity_search_with_score(question, k=top_k)
    relevant_chunks = [doc.page_content for doc, score in relevant_docs]
    context = "\n\n".join(relevant_chunks)
    scores = [score for doc, score in relevant_docs]
    
    print(f"En benzer {top_k} bÃ¶lÃ¼m bulundu")
    print(f"Benzerlik skorlarÄ±: {scores}")
    
    return context

############################################
########## 7- SETUP LLM CHAIN ##############
############################################

def setup_llm_chain(model_name="qwen2.5:7b-instruct-q4_K_M", temperature=0):
    """LLM ve prompt chain'i hazÄ±rla"""
    print("Lokal Qwen modeli hazÄ±rlanÄ±yor...")
    
    prompt_template = PromptTemplate.from_template("""
Sen CHP (Cumhuriyet Halk Partisi) hakkÄ±nda bilgi veren bir asistansÄ±n.

AÅŸaÄŸÄ±daki CHP Parti TÃ¼zÃ¼ÄŸÃ¼ bÃ¶lÃ¼mÃ¼ne gÃ¶re soruyu yanÄ±tla:

{context}

KullanÄ±cÄ±nÄ±n Sorusu: {question}

YanÄ±t KurallarÄ±:
- Kibar, nazik ve bilgilendirici ol
- DoÄŸrudan cevap ver, kaynak belirtme
- EÄŸer ilgili bilgi yukardaki metinde yoksa: "Bu konuda parti tÃ¼zÃ¼ÄŸÃ¼nde detaylÄ± bilgi bulamadÄ±m. Daha fazla bilgi iÃ§in https://chp.org.tr/ adresini ziyaret edebilirsiniz."

YanÄ±t:
""")
    
    llm = Ollama(model=model_name, temperature=temperature)
    chain = prompt_template | llm | StrOutputParser()
    
    return chain

############################################
########## 8- GENERATE ANSWER ##############
############################################

def generate_answer(chain, context, question):
    """LLM ile cevap Ã¼ret"""
    response = chain.invoke({"context": context, "question": question})
    return response

############################################
############ 9- CREATE MAIN ################
############################################

def main():
    """Ana program - Ã§oklu soru sorma Ã¶zelliÄŸi ile"""
    
    # 1. PDF'i yÃ¼kle ve hazÄ±rla
    pages = load_pdf("../data/chp.pdf")
    chunks = chunk_documents(pages)
    
    # 2. Embedding ve Vector DB
    embeddings = load_embeddings()
    vectorstore = create_vectorstore(chunks, embeddings)
    
    # 3. LLM Chain hazÄ±rla
    chain = setup_llm_chain()
    
    # 4. Soru-cevap dÃ¶ngÃ¼sÃ¼
    print("\n" + "="*60)
    print("CHP Parti TÃ¼zÃ¼ÄŸÃ¼ - Soru-Cevap Sistemi (LOKAL QWEN)")
    print("="*60)
    print("Ã‡Ä±kmak iÃ§in 'q' veya 'quit' yazÄ±n\n")
    
    while True:
        question = input("\nSorunuz: ").strip()
        
        # Ã‡Ä±kÄ±ÅŸ kontrolÃ¼
        if question.lower() in ['q', 'quit', 'exit', 'Ã§Ä±kÄ±ÅŸ']:
            print("\nGÃ¶rÃ¼ÅŸmek Ã¼zere! ğŸ‘‹")
            break
        
        if not question:
            print("LÃ¼tfen bir soru yazÄ±n.")
            continue
        
        # Cevap Ã¼ret
        context = search_similar_docs(vectorstore, question)
        response = generate_answer(chain, context, question)
        
        print("\n" + "="*60)
        print("Cevap:")
        print("="*60)
        print(response)
        print("\n" + "="*60)

############################################
################ 10- RUN ###################
############################################

if __name__ == "__main__":
    main()
